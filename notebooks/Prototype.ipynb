{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cec8e20-8abb-4448-85ec-37d92ce500a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.system import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5d338c-72c5-4633-945d-242226493121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_claude_bedrock_model(model_id: str, temperature: int = 0.0) -> BedrockChat:\n",
    "    return BedrockChat(\n",
    "        region_name=\"us-east-1\",\n",
    "        credentials_profile_name=\"default\",\n",
    "        model_id=model_id,\n",
    "        model_kwargs={\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 4096\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1eb447-1b9d-47c9-8d7a-16ffa929b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialist_message = \"\"\"You are a specialist in machine learning, artificial intelligence, programming, algorithms,\n",
    "engineering, mathematics and natural sciences. You will be given a specific task to solve. Your goal is to provide a solution\n",
    "that is accurate, clean and correct. Your response will then be read by a critic. The critic's task is to analyse your work and\n",
    "find any inaccuracies, errors or areas to improve. The critic will be friendly - their role is not to be picky, but rather to cooperate\n",
    "with you to refine the response to a state where you can both agree it meets the required standards. Remember that <<you do not have to\n",
    "agree with the critic's remarks if you think they are wrong!>>. This is very important because it is better to disagree and have a\n",
    "meaningful discussion then to return a suboptimal answer. Also, be sure to return a verbose chain of thought. For example, if you are to\n",
    "analyse a piece of text or code, highlight specific lines to which you have remarks. If you are prompted to provide a solution to a\n",
    "mathematical problem, provide a step-by-step reasoning that led you towards the solution.\"\"\".replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d578eba-93e6-4513-9fde-97d821065570",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_message = \"\"\"You are a specialist in machine learning, artificial intelligence, programming, algorithms,\n",
    "engineering, mathematics and natural sciences. You will be given a response to a question that was written by another specialist in\n",
    "the listed fields. Your task is to analyse the response thoroughly and in detail, and detect any potential inconsistencies, errors, or\n",
    "other flaws. Make sure your analysis is extensive. Do not be afraid to point out errors. Be sure to pay attemtion to things like:\n",
    "- Did the specialist thoroughly and carefuly carry out the task they were assigned?\n",
    "- Is the specialist's response correct and factual?\n",
    "- Is the specialist's reasoning clear, coherent and correct?\n",
    "- Is the content of the specialist's response substantial and objective?\n",
    "- Is the specialist's response easy to understand?\n",
    "It is ok to find areas to improve that you have not noticed in previous messages. It is also ok to ask for changes multiple times\n",
    "if you think there is still room for improvement in the response. When asking for a follow-up response, please outline your remarks\n",
    "providing as much details as you can. Please ask for a corrected version even if the things you point out are minor. At the end of your\n",
    "response, determine if you FULLY agree with the specialist regarding every detail of the response. If you are 100% aligned, and only\n",
    "then, end your message with the <AGREE> token. If there are even minor remarks or suggestions on your end, do not return <AGREE>.\"\"\".replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b018416-33e4-4d7a-8142-e431d422ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "<PROVIDE TASK>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c357950-b536-4c80-bb49-644161b5d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = instantiate_claude_bedrock_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "904fd64f-94ac-4261-a061-3e3db040a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFormatting:\n",
    "    BOLD = \"\\033[1m\"\n",
    "    END = \"\\033[0m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    RED = \"\\033[91m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e902917-b030-4409-9bb1-06972d7ba7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialist_memory = [SystemMessage(specialist_message), HumanMessage(task)]\n",
    "critic_memory = [SystemMessage(critic_message)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "011006da-dcfe-4d55-ae6a-ae60036733ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTASK\u001b[0m\n",
      "<code>\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/__init__.py\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/rl/__init__.py\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/rl/action.py\n",
      "import pydantic\n",
      "\n",
      "\n",
      "class Action(pydantic.BaseModel):\n",
      "    material: str\n",
      "\n",
      "\n",
      "class AddLayerAction(Action):\n",
      "    thickness_um: float\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/rl/environment.py\n",
      "import glob\n",
      "import os\n",
      "from typing import List\n",
      "\n",
      "import gymnasium as gym\n",
      "import numpy as np\n",
      "import tmm\n",
      "\n",
      "from multilayerai.entity import Requirement\n",
      "from multilayerai.entity.material import AIR\n",
      "from multilayerai.ml.rl.action import AddLayerAction, Action\n",
      "from multilayerai.utils.parser.refractiveindex_info import RefractiveIndexInfoCsvParser\n",
      "\n",
      "\n",
      "class TmmFeedbackEnvironment(gym.Env):\n",
      "    _WAVELENGTH_BOUND_LO = 3\n",
      "    _WAVELENGTH_BOUND_HI = 14\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        goal: List[Requirement],\n",
      "        refractive_index_assets_dir: str,\n",
      "        wavelength_granularity_um: float,\n",
      "    ):\n",
      "        self._goal = goal\n",
      "        self._refractive_index_functions_by_alias = {\n",
      "            RefractiveIndexInfoCsvParser.get_alias(path): RefractiveIndexInfoCsvParser(\n",
      "                path\n",
      "            ).function\n",
      "            for path in glob.glob(os.path.join(refractive_index_assets_dir, \"**.csv\"))\n",
      "        }\n",
      "        self._action_history: List[AddLayerAction] = []\n",
      "        self._wavelength_points = (\n",
      "            int(\n",
      "                (self._WAVELENGTH_BOUND_HI - self._WAVELENGTH_BOUND_LO)\n",
      "                / wavelength_granularity_um\n",
      "            )\n",
      "            + 1\n",
      "        )\n",
      "\n",
      "    def step(self, action: Action):\n",
      "        self._validate_action(action)\n",
      "        truncated = False\n",
      "        if action.material == \"<EOS>\":\n",
      "            reward = self._calculate_reward()\n",
      "            terminated = True\n",
      "        else:\n",
      "            self._action_history.append(action)\n",
      "            reward = 0\n",
      "            terminated = False\n",
      "        observation = self._get_obs()\n",
      "        return observation, reward, terminated, truncated\n",
      "\n",
      "    def _validate_action(self, action: Action):\n",
      "        if not isinstance(action, Action):\n",
      "            raise ValueError(f\"Encountered unknown action type {type(action)}\")\n",
      "        if isinstance(action, AddLayerAction):\n",
      "            if action.material not in self._refractive_index_functions_by_alias:\n",
      "                raise ValueError(\n",
      "                    f\"Encountered unknown material {action.material} for action: {action}\"\n",
      "                )\n",
      "            if action.thickness_um is None or action.thickness_um < 0:\n",
      "                raise ValueError(\n",
      "                    f\"Encountered invalid thickness {action.thickness_um} for action: {action}\"\n",
      "                )\n",
      "        else:\n",
      "            if action.material != \"<EOS>\":\n",
      "                raise ValueError(f\"Material for Action class should be <EOS>\")\n",
      "\n",
      "    def _calculate_reward(self) -> float:\n",
      "        materials = [action.material for action in self._action_history]\n",
      "        refractive_index_functions = [\n",
      "            self._refractive_index_functions_by_alias[material]\n",
      "            for material in materials\n",
      "        ]\n",
      "        thicknesses = [\n",
      "            float(\"inf\"),\n",
      "            *[action.thickness_um for action in self._action_history],\n",
      "            float(\"inf\"),\n",
      "        ]\n",
      "        partial_rewards = []\n",
      "        for wavelength_um in np.linspace(\n",
      "            self._WAVELENGTH_BOUND_LO,\n",
      "            self._WAVELENGTH_BOUND_HI,\n",
      "            self._wavelength_points,\n",
      "        ):\n",
      "            refractive_indices = [\n",
      "                AIR.refractive_index(wavelength_um),\n",
      "                *[function(wavelength_um) for function in refractive_index_functions],\n",
      "                AIR.refractive_index(wavelength_um),\n",
      "            ]\n",
      "            results = tmm.unpolarized_RT(\n",
      "                refractive_indices, thicknesses, th_0=0, lam_vac=wavelength_um\n",
      "            )\n",
      "            partial_rewards.extend(\n",
      "                self._calculate_partial_rewards(wavelength_um, results)\n",
      "            )\n",
      "        return np.mean(partial_rewards)\n",
      "\n",
      "    def _calculate_partial_rewards(\n",
      "        self, wavelength_um: float, results: dict\n",
      "    ) -> List[float]:\n",
      "        res = []\n",
      "        for requirement in self._goal:\n",
      "            if (\n",
      "                not requirement.wavelength_um_lo\n",
      "                <= wavelength_um\n",
      "                <= requirement.wavelength_um_hi\n",
      "            ):\n",
      "                continue  # assumes that the list of requirements is rather short, so no need to optimise here\n",
      "            property_value = results[requirement.optical_property.value]\n",
      "            res.append(-abs(property_value - requirement.expected_value))\n",
      "        return res\n",
      "\n",
      "    def _get_obs(self):\n",
      "        return {\"agent\": self._action_history, \"target\": self._goal}\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/rta_dataset.py\n",
      "from typing import List, Optional, Any, Tuple\n",
      "\n",
      "import h5py\n",
      "import numpy as np\n",
      "\n",
      "from multilayerai.ml.data.abstract_rta_dataset import (\n",
      "    ReflectanceTransmittanceAbsorptanceDataset,\n",
      ")\n",
      "\n",
      "\n",
      "class RTADataset(ReflectanceTransmittanceAbsorptanceDataset):\n",
      "    def __init__(\n",
      "        self,\n",
      "        dataset_path: str,\n",
      "        indices: Optional[List[int]] = None,\n",
      "        store_in_memory: bool = False,\n",
      "        **kwargs\n",
      "    ):\n",
      "        reader = h5py.File(dataset_path, \"r\")\n",
      "        indices = (\n",
      "            sorted(indices)\n",
      "            if indices is not None\n",
      "            else list(range(self._reader.attrs[\"index\"]))\n",
      "        )\n",
      "        super().__init__(dataset_path, indices, reader, store_in_memory)\n",
      "\n",
      "        self._results = (\n",
      "            reader[\"results\"][indices] if store_in_memory else reader[\"results\"]\n",
      "        )\n",
      "        self._num_columns = self._results.shape[1]\n",
      "        if store_in_memory:\n",
      "            self._reader.close()\n",
      "\n",
      "    def __getitem__(self, raw_index: int) -> Any:\n",
      "        row, col = self._to_row_and_col(raw_index)\n",
      "        R = self._results[row, 3 * col]\n",
      "        T = self._results[row, 3 * col + 1]\n",
      "        A = self._results[row, 3 * col + 2]\n",
      "\n",
      "        wavelength = self.wavelengths_um[col]\n",
      "        thicknesses = self.thicknesses[row]\n",
      "        refractive_indices = self.refractive_indices[\n",
      "            row, self._max_layers * col : self._max_layers * (col + 1)\n",
      "        ]\n",
      "        num_layers = self.num_layers[row]\n",
      "\n",
      "        return {\n",
      "            \"R\": R,\n",
      "            \"T\": T,\n",
      "            \"A\": A,\n",
      "            \"wavelength_um\": wavelength,\n",
      "            \"thicknesses\": thicknesses,\n",
      "            \"refractive_indices_real\": np.real(refractive_indices),\n",
      "            \"refractive_indices_imag\": np.imag(refractive_indices),\n",
      "            \"num_layers\": num_layers,\n",
      "        }\n",
      "\n",
      "    def _to_row_and_col(self, raw_index: int) -> Tuple[int, int]:\n",
      "        \"\"\"\n",
      "        Maps the raw index from range [0, len(dataset)] to the subset of the HDF5 file defined by self._row_indices.\n",
      "        \"\"\"\n",
      "        index = raw_index if self._store_in_memory else self._indices[raw_index]\n",
      "        row = index % self._num_rows\n",
      "        col = index // self._num_rows\n",
      "        return row, col\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        return self._num_rows * (self._num_columns // 3)\n",
      "\n",
      "    def __del__(self):\n",
      "        if self._reader is not None:\n",
      "            self._reader.close()\n",
      "\n",
      "    def __getstate__(self):\n",
      "        self._reader = None\n",
      "        return self.__dict__\n",
      "\n",
      "    def __setstate__(self, state):\n",
      "        self.__dict__ = state\n",
      "        self._reader = h5py.File(self._dataset_path, \"r\")\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/__init__.py\n",
      "from multilayerai.ml.data.vocab_mappings import VocabMappings\n",
      "from multilayerai.ml.data.rta_dataset import RTADataset\n",
      "from multilayerai.ml.data.structure_from_rta_bands_dataset import (\n",
      "    StructureFromRTABandsDataset,\n",
      ")\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/abstract_rta_dataset.py\n",
      "import abc\n",
      "from typing import List, Tuple, Dict\n",
      "\n",
      "import h5py\n",
      "import numpy as np\n",
      "from numpy.typing import NDArray\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "from multilayerai.utils.standardization import StandardizationCoefficients\n",
      "\n",
      "\n",
      "class ReflectanceTransmittanceAbsorptanceDataset(Dataset, abc.ABC):\n",
      "    def __init__(\n",
      "        self,\n",
      "        dataset_path: str,\n",
      "        indices: List[int],\n",
      "        reader: h5py.File,\n",
      "        store_in_memory: bool = False,\n",
      "    ):\n",
      "        self._dataset_path = dataset_path\n",
      "        self._reader = reader\n",
      "\n",
      "        self._index = self._reader.attrs[\"index\"]\n",
      "        self._indices = sorted(indices)\n",
      "        self._store_in_memory = store_in_memory\n",
      "        self._max_layers = self._reader.attrs[\"max_layers\"]\n",
      "        self._num_layers = (\n",
      "            self._reader[\"num_layers\"][self._indices]\n",
      "            if store_in_memory\n",
      "            else self._reader[\"num_layers\"]\n",
      "        )\n",
      "        self._structure_ids = (\n",
      "            self._reader[\"structure_ids\"][self._indices]\n",
      "            if store_in_memory\n",
      "            else self._reader[\"structure_ids\"]\n",
      "        )\n",
      "        self._materials = (\n",
      "            self._reader[\"materials\"][self._indices]\n",
      "            if store_in_memory\n",
      "            else self._reader[\"materials\"]\n",
      "        )\n",
      "        self._refractive_indices = (\n",
      "            self._reader[\"refractive_indices\"][self._indices]\n",
      "            if store_in_memory\n",
      "            else self._reader[\"refractive_indices\"]\n",
      "        )\n",
      "        self._thicknesses = (\n",
      "            self._reader[\"thicknesses\"][self._indices]\n",
      "            if store_in_memory\n",
      "            else self._reader[\"thicknesses\"]\n",
      "        )\n",
      "        self._wavelengths_um = (\n",
      "            self._reader.attrs[\"wavelengths_um\"]\n",
      "            if store_in_memory\n",
      "            else self._reader.attrs[\"wavelengths_um\"]\n",
      "        )\n",
      "        self._num_rows = len(self._indices)\n",
      "\n",
      "    @property\n",
      "    def max_layers(self) -> int:\n",
      "        return self._max_layers\n",
      "\n",
      "    @property\n",
      "    def num_layers(self) -> NDArray[int]:\n",
      "        return (\n",
      "            self._num_layers\n",
      "            if self._store_in_memory\n",
      "            else self._num_layers[self._indices]\n",
      "        )\n",
      "\n",
      "    @property\n",
      "    def materials(self) -> NDArray[str]:\n",
      "        return (\n",
      "            self._materials if self._store_in_memory else self._materials[self._indices]\n",
      "        )\n",
      "\n",
      "    @property\n",
      "    def structure_ids(self) -> NDArray[str]:\n",
      "        return (\n",
      "            self._structure_ids\n",
      "            if self._store_in_memory\n",
      "            else self._structure_ids[self._indices]\n",
      "        )\n",
      "\n",
      "    @staticmethod\n",
      "    def read_structure_ids(dataset_path: str) -> NDArray[str]:\n",
      "        with h5py.File(dataset_path, \"r\") as reader:\n",
      "            return reader[\"structure_ids\"][: reader.attrs[\"index\"]]\n",
      "\n",
      "    @property\n",
      "    def index(self) -> int:\n",
      "        return self._index\n",
      "\n",
      "    @property\n",
      "    def wavelengths_um(self) -> NDArray[float]:\n",
      "        return self._wavelengths_um\n",
      "\n",
      "    @property\n",
      "    def refractive_indices(self) -> NDArray[complex]:\n",
      "        return (\n",
      "            self._refractive_indices\n",
      "            if self._store_in_memory\n",
      "            else self._refractive_indices[self._indices]\n",
      "        )\n",
      "\n",
      "    @property\n",
      "    def thicknesses(self) -> NDArray[float]:\n",
      "        return (\n",
      "            self._thicknesses\n",
      "            if self._store_in_memory\n",
      "            else self._thicknesses[self._indices]\n",
      "        )\n",
      "\n",
      "    def _to_row_and_col(self, raw_index: int) -> Tuple[int, int]:\n",
      "        \"\"\"\n",
      "        Maps the raw index from range [0, len(dataset)] to the subset of the HDF5 file defined by self._row_indices.\n",
      "        \"\"\"\n",
      "        index = raw_index if self._store_in_memory else self._indices[raw_index]\n",
      "        row = index % self._num_rows\n",
      "        col = index // self._num_rows\n",
      "        return row, col\n",
      "\n",
      "    def get_standardization_coefficients(\n",
      "        self,\n",
      "    ) -> Dict[str, StandardizationCoefficients]:\n",
      "        coeffs = {}\n",
      "        for property, values in (\n",
      "            (\"num_layers\", self.num_layers),\n",
      "            (\"thicknesses\", self.thicknesses),\n",
      "            (\"refractive_indices_real\", np.real(self.refractive_indices)),\n",
      "            (\"refractive_indices_imag\", np.imag(self.refractive_indices)),\n",
      "            (\"wavelengths_um\", self.wavelengths_um),\n",
      "        ):\n",
      "            mean = np.mean(values[np.isfinite(values)])\n",
      "            stddev = np.std(values[np.isfinite(values)])\n",
      "            coeffs[property] = StandardizationCoefficients(mean, stddev)\n",
      "        return coeffs\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/vocab_mappings.py\n",
      "from typing import Dict, Set\n",
      "\n",
      "\n",
      "class VocabMappings:\n",
      "    PADDING_TOKEN = \"<PAD>\"\n",
      "\n",
      "    def __init__(\n",
      "        self, material_to_idx: Dict[str, int], idx_to_material: Dict[int, str]\n",
      "    ):\n",
      "        self.material_to_idx = material_to_idx\n",
      "        self.idx_to_material = idx_to_material\n",
      "        self.padding_token_idx = material_to_idx[VocabMappings.PADDING_TOKEN]\n",
      "\n",
      "    @classmethod\n",
      "    def from_materials(cls, materials: Set[str]) -> \"VocabMappings\":\n",
      "        vocab = {VocabMappings.PADDING_TOKEN}\n",
      "        vocab.update(materials)\n",
      "        material_to_idx = {mat: idx for idx, mat in enumerate(vocab)}\n",
      "        idx_to_material = {idx: mat for mat, idx in material_to_idx.items()}\n",
      "        return cls(\n",
      "            material_to_idx=material_to_idx,\n",
      "            idx_to_material=idx_to_material,\n",
      "        )\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.material_to_idx)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/bands.py\n",
      "import copy\n",
      "from typing import List\n",
      "\n",
      "\n",
      "class RTABandRequirement:\n",
      "    @staticmethod\n",
      "    def vector(\n",
      "        property: str,\n",
      "        wavelength_um_lo: float,\n",
      "        wavelength_um_hi: float,\n",
      "        value: float,\n",
      "    ) -> List[float]:\n",
      "        if property not in {\"R\", \"T\", \"A\"}:\n",
      "            raise ValueError(f\"property must be one of 'R', 'T', 'A', got: {property}\")\n",
      "        if not 0 <= value <= 1:\n",
      "            raise ValueError(f\"value must be in range [0, 1], got: {value}\")\n",
      "        if wavelength_um_lo > wavelength_um_hi:\n",
      "            raise ValueError(\n",
      "                f\"wavelength_um_lo must be less than or equal to wavelength_um_hi, \"\n",
      "                f\"got: {wavelength_um_lo} and {wavelength_um_hi}\"\n",
      "            )\n",
      "        return [\n",
      "            1.0 if property == \"R\" else 0.0,\n",
      "            1.0 if property == \"T\" else 0.0,\n",
      "            1.0 if property == \"A\" else 0.0,\n",
      "            wavelength_um_lo,\n",
      "            wavelength_um_hi,\n",
      "            value,\n",
      "            0.0,  # is_padding element\n",
      "        ]\n",
      "\n",
      "\n",
      "class RTABandsRequirementsBuilder:\n",
      "    def __init__(self):\n",
      "        self._requirements = []\n",
      "\n",
      "    def add_requirement(\n",
      "        self,\n",
      "        property: str,\n",
      "        wavelength_um_lo: float,\n",
      "        wavelength_um_hi: float,\n",
      "        value: float,\n",
      "    ) -> \"RTABandsRequirementsBuilder\":\n",
      "        self._requirements.append(\n",
      "            RTABandRequirement.vector(\n",
      "                property, wavelength_um_lo, wavelength_um_hi, value\n",
      "            )\n",
      "        )\n",
      "        return self\n",
      "\n",
      "    def to_vector(self) -> List[List[float]]:\n",
      "        return copy.deepcopy(self._requirements)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/dataloader.py\n",
      "import multiprocessing\n",
      "\n",
      "from torch.utils.data import DataLoader, Dataset\n",
      "\n",
      "\n",
      "def create_dataloader(\n",
      "    dataset: Dataset,\n",
      "    batch_size: int,\n",
      "    shuffle: bool,\n",
      "    num_workers: int = max(1, multiprocessing.cpu_count() - 1),\n",
      ") -> DataLoader:\n",
      "    return DataLoader(\n",
      "        dataset,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=shuffle,\n",
      "        num_workers=num_workers,\n",
      "    )\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/data/structure_from_rta_bands_dataset.py\n",
      "import logging\n",
      "from typing import List, Optional, Any, Tuple, Set\n",
      "\n",
      "import h5py\n",
      "import numpy as np\n",
      "import tqdm\n",
      "from more_itertools import consecutive_groups\n",
      "from numpy.typing import NDArray\n",
      "\n",
      "from multilayerai.ml.data import VocabMappings\n",
      "from multilayerai.ml.data.abstract_rta_dataset import (\n",
      "    ReflectanceTransmittanceAbsorptanceDataset,\n",
      ")\n",
      "from multilayerai.ml.data.bands import RTABandRequirement\n",
      "\n",
      "\n",
      "class StructureFromRTABandsDataset(ReflectanceTransmittanceAbsorptanceDataset):\n",
      "    def __init__(\n",
      "        self,\n",
      "        dataset_path: str,\n",
      "        vocab_mappings: VocabMappings,\n",
      "        precalculated_rta_bands_path: Optional[str] = None,\n",
      "        indices: Optional[List[int]] = None,\n",
      "        store_in_memory: bool = False,\n",
      "        augment: bool = False,\n",
      "        logger: logging.Logger = None,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        reader = h5py.File(dataset_path, \"r\")\n",
      "        indices = indices if indices else list(range(reader.attrs[\"index\"]))\n",
      "        if store_in_memory:\n",
      "            if precalculated_rta_bands_path:\n",
      "                indices_set = set(indices)\n",
      "                logger.info(\n",
      "                    f\"Loading precalculated RTA bands from {precalculated_rta_bands_path}\"\n",
      "                )\n",
      "                with open(precalculated_rta_bands_path, \"rb\") as file:\n",
      "                    self._results = [\n",
      "                        bands\n",
      "                        for row_idx, bands in enumerate(np.load(file))\n",
      "                        if row_idx in indices_set and not all(bands[:, -1])\n",
      "                    ]\n",
      "                    indices = list(range(len(self._results)))\n",
      "            else:\n",
      "                indices_tmp = []\n",
      "                bands = []\n",
      "                for row_idx in tqdm.tqdm(indices, desc=\"Finding RTA bands...\"):\n",
      "                    bands_single = self.get_rta_bands(\n",
      "                        row_idx,\n",
      "                        rta_results=reader[\"results\"],\n",
      "                        wavelengths_um=reader.attrs[\"wavelengths_um\"],\n",
      "                    )\n",
      "                    if bands_single:\n",
      "                        indices.append(row_idx)\n",
      "                        bands.append(bands_single)\n",
      "                self._results = bands\n",
      "                indices = indices_tmp\n",
      "            self._max_bands_length = max(len(bands) for bands in self._results)\n",
      "        else:\n",
      "            band_lengths = sorted(\n",
      "                [\n",
      "                    len(\n",
      "                        self.get_rta_bands(\n",
      "                            row_idx,\n",
      "                            rta_results=reader[\"results\"],\n",
      "                            wavelengths_um=reader.attrs[\"wavelengths_um\"],\n",
      "                        )\n",
      "                    )\n",
      "                    for row_idx in tqdm.tqdm(indices, desc=\"Finding RTA bands...\")\n",
      "                ]\n",
      "            )\n",
      "            self._results = None\n",
      "            self._max_bands_length = max(band_lengths)\n",
      "        super().__init__(dataset_path, indices, reader, store_in_memory)\n",
      "        self._vocab_mappings = vocab_mappings\n",
      "        self._augment = augment\n",
      "        if logger:\n",
      "            logger.info(f\"Found {len(self._indices)} valid rows\")\n",
      "\n",
      "    def __getitem__(self, idx: int) -> Any:\n",
      "        idx_eff = idx if self._store_in_memory else self._indices[idx]\n",
      "        bands = (\n",
      "            self._results[idx_eff]\n",
      "            if self._store_in_memory\n",
      "            else self.get_rta_bands(\n",
      "                self._indices[idx_eff], self._results, self.wavelengths_um\n",
      "            )\n",
      "        )\n",
      "        if self._augment:\n",
      "            bands = np.array([band for band in bands if band[-1] == 0])\n",
      "            bands_subset_count = np.random.randint(1, len(bands) + 1)\n",
      "            indices_subset = np.random.choice(len(bands), bands_subset_count, replace=False)\n",
      "            bands = bands[indices_subset]\n",
      "            bands[:, 3] = np.random.uniform(bands[:, 3], bands[:, 4])\n",
      "            bands[:, 4] = np.random.uniform(bands[:, 3], bands[:, 4])\n",
      "\n",
      "        padded_bands = list(bands) + [self.get_band_padding_vector()] * (\n",
      "            self._max_bands_length - len(bands)\n",
      "        )\n",
      "\n",
      "        # Start from 1 because we assume the first layer is always air\n",
      "        thicknesses = self.thicknesses[idx_eff]\n",
      "        materials = [\n",
      "            self._vocab_mappings.material_to_idx[mat.decode(\"utf-8\")]\n",
      "            if mat\n",
      "            else self._vocab_mappings.padding_token_idx\n",
      "            for mat in self.materials[idx_eff]\n",
      "        ]\n",
      "        return {\n",
      "            \"band_requirements\": np.array(padded_bands),\n",
      "            \"thicknesses\": np.array(thicknesses),\n",
      "            \"materials\": np.array(materials),\n",
      "            \"num_layers\": self.num_layers[idx_eff],\n",
      "        }\n",
      "\n",
      "    @staticmethod\n",
      "    def get_rta_bands(\n",
      "        row: int, rta_results: NDArray[float], wavelengths_um: NDArray[float]\n",
      "    ) -> List[List[float]]:\n",
      "        R_indices = StructureFromRTABandsDataset._find_satisficing_indices(\n",
      "            rta_results[row, ::3], 0.025, 0.975, 0.4875, 0.5125\n",
      "        )\n",
      "        T_indices = StructureFromRTABandsDataset._find_satisficing_indices(\n",
      "            rta_results[row, 1::3], 0.025, 0.975, 0.4875, 0.5125\n",
      "        )\n",
      "        A_indices = StructureFromRTABandsDataset._find_satisficing_indices(\n",
      "            rta_results[row, 2::3], 0.025, 0.975, 0.4875, 0.5125\n",
      "        )\n",
      "\n",
      "        R_ranges, T_ranges, A_ranges = [\n",
      "            StructureFromRTABandsDataset._to_contiguous_ranges(*indices)\n",
      "            for indices in (R_indices, T_indices, A_indices)\n",
      "        ]\n",
      "        return [\n",
      "            vector\n",
      "            for property, ranges in zip((\"R\", \"T\", \"A\"), (R_ranges, T_ranges, A_ranges))\n",
      "            for ranges_single_idx, ranges_single in enumerate(ranges)\n",
      "            for vector in StructureFromRTABandsDataset._ranges_to_vectors(\n",
      "                property,\n",
      "                ranges_single,\n",
      "                value=0.0\n",
      "                if ranges_single_idx == 0\n",
      "                else 0.5\n",
      "                if ranges_single_idx == 1\n",
      "                else 1.0,\n",
      "                wavelengths_um=wavelengths_um,\n",
      "            )\n",
      "        ]\n",
      "\n",
      "    @staticmethod\n",
      "    def get_band_padding_vector() -> List[float]:\n",
      "        return [0, 0, 0, 0, 0, 0, 1]\n",
      "\n",
      "    @staticmethod\n",
      "    def _find_satisficing_indices(\n",
      "        input_array: NDArray[float],\n",
      "        lower_bound: float,\n",
      "        upper_bound: float,\n",
      "        middle_bound_lo: float,\n",
      "        middle_bound_hi: float,\n",
      "    ) -> Tuple[List[int], List[int], List[int]]:\n",
      "        lower_arr = np.where(input_array < lower_bound)[0].tolist()\n",
      "        upper_arr = np.where(input_array > upper_bound)[0].tolist()\n",
      "        middle_arr = np.where(\n",
      "            (middle_bound_lo < input_array) & (input_array < middle_bound_hi)\n",
      "        )[0].tolist()\n",
      "        return lower_arr, upper_arr, middle_arr\n",
      "\n",
      "    @staticmethod\n",
      "    def _to_contiguous_ranges(\n",
      "        *indices_arrs: Tuple[List[int], List[int], List[int]]\n",
      "    ) -> List[List[Tuple[int, int]]]:\n",
      "        return [\n",
      "            [\n",
      "                (group[0], group[-1])\n",
      "                for group in (list(g) for g in consecutive_groups(indices))\n",
      "            ]\n",
      "            for indices in indices_arrs\n",
      "        ]\n",
      "\n",
      "    @staticmethod\n",
      "    def _ranges_to_vectors(\n",
      "        property: str,\n",
      "        ranges: List[Tuple[int, int]],\n",
      "        value: float,\n",
      "        wavelengths_um: NDArray[float],\n",
      "    ) -> List[List[float]]:\n",
      "        return [\n",
      "            RTABandRequirement.vector(\n",
      "                property,\n",
      "                wavelengths_um[range_start],\n",
      "                wavelengths_um[range_end],\n",
      "                value,\n",
      "            )\n",
      "            for range_start, range_end in ranges\n",
      "        ]\n",
      "\n",
      "    @staticmethod\n",
      "    def read_unique_materials(dataset_path: str) -> Set[str]:\n",
      "        with h5py.File(dataset_path, \"r\") as reader:\n",
      "            return set(\n",
      "                [\n",
      "                    mat.decode(\"utf-8\")\n",
      "                    for mat in reader[\"materials\"][: reader.attrs[\"index\"]].flatten()\n",
      "                ]\n",
      "            )\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        return len(self._indices)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/structure_generator_from_rta_bands_lightning_wrapper.py\n",
      "from typing import Union, Dict, Tuple, Optional, Any\n",
      "\n",
      "import pytorch_lightning as pl\n",
      "import torch.nn\n",
      "from torch import Tensor\n",
      "from torch.optim.lr_scheduler import LambdaLR\n",
      "\n",
      "from multilayerai.ml.data import VocabMappings\n",
      "from multilayerai.utils.standardization import StandardizationCoefficients\n",
      "\n",
      "\n",
      "class StructureGeneratorFromRTABandsLightningWrapper(pl.LightningModule):\n",
      "    def __init__(\n",
      "        self,\n",
      "        backbone: torch.nn.Module,\n",
      "        vocab_mappings: VocabMappings,\n",
      "        max_steps: int,\n",
      "        standardization_coefficients: Optional[Dict[str, StandardizationCoefficients]],\n",
      "        initial_lr: float,\n",
      "        num_lr_warmup_epochs: float,\n",
      "        final_lr_fraction: float,\n",
      "        beta_1: float = 0.9,\n",
      "        beta_2: float = 0.999,\n",
      "        eps: float = 1e-8,\n",
      "        weight_decay: float = 0.0,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self._backbone = backbone\n",
      "        self.save_hyperparameters(ignore=[\"backbone\"])\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        band_requirements: Tensor,\n",
      "        target_tensor: Tensor,\n",
      "    ) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "        return self._backbone(band_requirements.float(), target_tensor)\n",
      "\n",
      "    def training_step(self, batch: Dict[str, Tensor], _) -> Union[Tensor, dict]:\n",
      "        return self._step(batch, is_training=True)\n",
      "\n",
      "    def validation_step(self, batch: Dict[str, Tensor], _) -> Union[Tensor, dict]:\n",
      "        return self._step(batch, is_training=False)\n",
      "\n",
      "    def _step(self, batch: Dict[str, Tensor], is_training: bool) -> Union[Tensor, dict]:\n",
      "        materials_gt = batch[\"materials\"]\n",
      "        thicknesses_gt = torch.where(\n",
      "            batch[\"thicknesses\"].isinf(), 0, batch[\"thicknesses\"]\n",
      "        )\n",
      "        is_inf_gt = batch[\"thicknesses\"].isinf()\n",
      "        target_tensor = torch.stack((materials_gt, thicknesses_gt, is_inf_gt), dim=-1)\n",
      "        materials_gt = materials_gt[:, 1:]\n",
      "        thicknesses_gt = thicknesses_gt[:, 1:]\n",
      "        is_inf_gt = is_inf_gt[:, 1:]\n",
      "\n",
      "        materials_logits, thicknesses_pred, is_inf_pred = self(\n",
      "            batch[\"band_requirements\"], target_tensor\n",
      "        )\n",
      "        materials_logits = materials_logits[:, :-1, :]\n",
      "        materials_logits_argmax = torch.argmax(materials_logits, dim=-1)\n",
      "        n_rows, n_cols = materials_logits_argmax.size()\n",
      "        rows = torch.arange(n_rows).unsqueeze(1).expand(n_rows, n_cols)\n",
      "        cols = torch.arange(n_cols).unsqueeze(0).expand(n_rows, n_cols)\n",
      "\n",
      "        thicknesses_pred = thicknesses_pred[:, :-1, :][\n",
      "            rows, cols, materials_logits_argmax\n",
      "        ]\n",
      "        is_inf_pred = is_inf_pred[:, :-1, :][rows, cols, materials_logits_argmax]\n",
      "\n",
      "        materials_loss = torch.nn.functional.cross_entropy(\n",
      "            materials_logits.reshape(-1, materials_logits.size(-1)),\n",
      "            materials_gt.reshape(-1),\n",
      "            reduction=\"none\",\n",
      "        )\n",
      "        thicknesses_loss = torch.nn.functional.mse_loss(\n",
      "            thicknesses_pred.squeeze(-1), thicknesses_gt, reduction=\"none\"\n",
      "        ) / (thicknesses_gt + 1e-8)\n",
      "        thicknesses_mask = torch.logical_and(\n",
      "            torch.logical_not(is_inf_gt),\n",
      "            materials_gt != self.hparams.vocab_mappings.padding_token_idx,\n",
      "        )\n",
      "        thicknesses_loss = 0.5 * thicknesses_loss[thicknesses_mask].view(-1)\n",
      "        is_inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
      "            is_inf_pred.squeeze(-1), is_inf_gt.float(), reduction=\"none\"\n",
      "        )\n",
      "        is_inf_loss = 2 * is_inf_loss[\n",
      "            materials_gt != self.hparams.vocab_mappings.padding_token_idx\n",
      "        ].view(-1)\n",
      "        loss = (\n",
      "            torch.sum(\n",
      "                materials_loss.mean() + thicknesses_loss.mean() + is_inf_loss.mean()\n",
      "            )\n",
      "            / 3\n",
      "        )\n",
      "        self.log(\n",
      "            \"loss\" if is_training else \"val_loss\",\n",
      "            loss,\n",
      "            on_step=True,\n",
      "            on_epoch=True,\n",
      "            prog_bar=True,\n",
      "            logger=True,\n",
      "        )\n",
      "        return loss\n",
      "\n",
      "    def configure_optimizers(self) -> Any:\n",
      "        def lr_lambda(current_step):\n",
      "            num_warmup_steps = (\n",
      "                self.hparams.num_lr_warmup_epochs * self.hparams.max_steps\n",
      "            )\n",
      "\n",
      "            if current_step < num_warmup_steps:\n",
      "                # Linear warmup\n",
      "                return float(current_step) / float(max(1, num_warmup_steps))\n",
      "            else:\n",
      "                # Linear decay\n",
      "                decay_steps = self.hparams.max_steps - num_warmup_steps\n",
      "                return self.hparams.final_lr_fraction + (\n",
      "                    1 - self.hparams.final_lr_fraction\n",
      "                ) * (\n",
      "                    float(decay_steps - (current_step - num_warmup_steps))\n",
      "                    / float(max(1, decay_steps))\n",
      "                )\n",
      "\n",
      "        optimizer = torch.optim.Adam(\n",
      "            params=self._backbone.parameters(),\n",
      "            lr=self.hparams.initial_lr,\n",
      "            betas=(self.hparams.beta_1, self.hparams.beta_2),\n",
      "            eps=self.hparams.eps,\n",
      "            weight_decay=self.hparams.weight_decay,\n",
      "        )\n",
      "        scheduler = {\n",
      "            \"scheduler\": LambdaLR(optimizer, lr_lambda),\n",
      "            \"interval\": \"step\",\n",
      "            \"frequency\": 1,\n",
      "        }\n",
      "        return [optimizer], [scheduler]\n",
      "\n",
      "    @staticmethod\n",
      "    def embedding_size() -> int:\n",
      "        return 7\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/__init__.py\n",
      "from multilayerai.ml.model.rta_predictor_lightning_wrapper import (\n",
      "    RTAPredictorLightningWrapper,\n",
      ")\n",
      "from multilayerai.ml.model.structure_generator_from_rta_bands_lightning_wrapper import (\n",
      "    StructureGeneratorFromRTABandsLightningWrapper,\n",
      ")\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/rta_predictor_lightning_wrapper.py\n",
      "from typing import Union, Dict, Tuple, Optional, Any\n",
      "\n",
      "import pytorch_lightning as pl\n",
      "import torch.nn\n",
      "from torch import Tensor\n",
      "from torch.optim.lr_scheduler import LambdaLR\n",
      "\n",
      "from multilayerai.utils.standardization import StandardizationCoefficients\n",
      "\n",
      "\n",
      "class RTAPredictorLightningWrapper(pl.LightningModule):\n",
      "    def __init__(\n",
      "        self,\n",
      "        backbone: torch.nn.Module,\n",
      "        max_steps: int,\n",
      "        standardization_coefficients: Optional[Dict[str, StandardizationCoefficients]],\n",
      "        initial_lr: float,\n",
      "        num_lr_warmup_epochs: float,\n",
      "        final_lr_fraction: float,\n",
      "        beta_1: float = 0.9,\n",
      "        beta_2: float = 0.999,\n",
      "        eps: float = 1e-8,\n",
      "        weight_decay: float = 0.0,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self._backbone = backbone\n",
      "        self.save_hyperparameters(ignore=[\"backbone\"])\n",
      "        (\n",
      "            self._mean_tensors,\n",
      "            self._stddev_tensors,\n",
      "        ) = self._create_standardization_tensors()\n",
      "\n",
      "    def forward(self, input: Tensor) -> Tensor:\n",
      "        return self._backbone(input)\n",
      "\n",
      "    def training_step(self, batch: Dict[str, Tensor], _) -> Union[Tensor, dict]:\n",
      "        return self._step(batch, is_training=True)\n",
      "\n",
      "    def validation_step(self, batch: Dict[str, Tensor], _) -> Union[Tensor, dict]:\n",
      "        return self._step(batch, is_training=False)\n",
      "\n",
      "    def _step(self, batch: Dict[str, Tensor], is_training: bool) -> Union[Tensor, dict]:\n",
      "        model_input, ground_truths = self.as_embedding(batch)\n",
      "        output = self(model_input.to(self.device))\n",
      "        loss = torch.nn.functional.l1_loss(output, ground_truths)\n",
      "        self.log(\n",
      "            \"loss\" if is_training else \"val_loss\",\n",
      "            loss,\n",
      "            on_step=True,\n",
      "            on_epoch=True,\n",
      "            prog_bar=True,\n",
      "            logger=True,\n",
      "        )\n",
      "        return loss\n",
      "\n",
      "    def configure_optimizers(self) -> Any:\n",
      "        def lr_lambda(current_step):\n",
      "            num_warmup_steps = (\n",
      "                self.hparams.num_lr_warmup_epochs * self.hparams.max_steps\n",
      "            )\n",
      "\n",
      "            if current_step < num_warmup_steps:\n",
      "                # Linear warmup\n",
      "                return float(current_step) / float(max(1, num_warmup_steps))\n",
      "            else:\n",
      "                # Linear decay\n",
      "                decay_steps = self.hparams.max_steps - num_warmup_steps\n",
      "                return self.hparams.final_lr_fraction + (\n",
      "                    1 - self.hparams.final_lr_fraction\n",
      "                ) * (\n",
      "                    float(decay_steps - (current_step - num_warmup_steps))\n",
      "                    / float(max(1, decay_steps))\n",
      "                )\n",
      "\n",
      "        optimizer = torch.optim.Adam(\n",
      "            params=self._backbone.parameters(),\n",
      "            lr=self.hparams.initial_lr,\n",
      "            betas=(self.hparams.beta_1, self.hparams.beta_2),\n",
      "            eps=self.hparams.eps,\n",
      "            weight_decay=self.hparams.weight_decay,\n",
      "        )\n",
      "        scheduler = {\n",
      "            \"scheduler\": LambdaLR(optimizer, lr_lambda),\n",
      "            \"interval\": \"step\",\n",
      "            \"frequency\": 1,\n",
      "        }\n",
      "        return [optimizer], [scheduler]\n",
      "\n",
      "    def as_embedding(\n",
      "        self,\n",
      "        input_dict: Dict[str, Tensor],\n",
      "    ) -> Tuple[Tensor, Tensor]:\n",
      "        batch_size = input_dict[\"thicknesses\"].size(0)\n",
      "        layers_dim = input_dict[\"thicknesses\"].size(1)\n",
      "        refractive_indices_real = torch.where(\n",
      "            torch.isnan(input_dict[\"refractive_indices_real\"]),\n",
      "            1,\n",
      "            input_dict[\"refractive_indices_real\"],\n",
      "        )\n",
      "        refractive_indices_imag = torch.where(\n",
      "            torch.isnan(input_dict[\"refractive_indices_imag\"]),\n",
      "            0,\n",
      "            input_dict[\"refractive_indices_imag\"],\n",
      "        )\n",
      "        thickness = torch.where(\n",
      "            torch.isinf(input_dict[\"thicknesses\"]), 0, input_dict[\"thicknesses\"]\n",
      "        )\n",
      "        wavelengths = input_dict[\"wavelength_um\"].unsqueeze(dim=1).repeat(1, layers_dim)\n",
      "        is_infinite_layer = torch.where(torch.isinf(input_dict[\"thicknesses\"]), 1, 0)\n",
      "        is_padding = (\n",
      "            torch.arange(layers_dim).expand(batch_size, layers_dim).to(self.device)\n",
      "            > input_dict[\"num_layers\"].unsqueeze(dim=1)\n",
      "        ).to(dtype=torch.float32)\n",
      "        embeddings = torch.stack(\n",
      "            [\n",
      "                refractive_indices_real,\n",
      "                refractive_indices_imag,\n",
      "                thickness,\n",
      "                wavelengths,\n",
      "                is_infinite_layer,\n",
      "                is_padding,\n",
      "            ],\n",
      "            dim=-1,\n",
      "        )\n",
      "        embeddings = embeddings - self._mean_tensors.to(\n",
      "            self.device\n",
      "        ) / self._stddev_tensors.to(self.device)\n",
      "        results = torch.stack(\n",
      "            (input_dict[\"R\"], input_dict[\"T\"], input_dict[\"A\"]), dim=-1\n",
      "        )\n",
      "        return embeddings.to(torch.float32), results.to(torch.float32)\n",
      "\n",
      "    @staticmethod\n",
      "    def embedding_size() -> int:\n",
      "        return 6\n",
      "\n",
      "    def _create_standardization_tensors(self) -> Tuple[Tensor, Tensor]:\n",
      "        if self.hparams.standardization_coefficients is None:\n",
      "            return torch.ones(5), torch.zeros(5)\n",
      "        mean_tensors = torch.tensor(\n",
      "            [\n",
      "                self.hparams.standardization_coefficients[\n",
      "                    \"refractive_indices_real\"\n",
      "                ].mean,\n",
      "                self.hparams.standardization_coefficients[\n",
      "                    \"refractive_indices_imag\"\n",
      "                ].mean,\n",
      "                self.hparams.standardization_coefficients[\"thicknesses\"].mean,\n",
      "                self.hparams.standardization_coefficients[\"wavelengths_um\"].mean,\n",
      "                0,\n",
      "                0,\n",
      "            ]\n",
      "        )\n",
      "        stddev_tensors = torch.tensor(\n",
      "            [\n",
      "                self.hparams.standardization_coefficients[\n",
      "                    \"refractive_indices_real\"\n",
      "                ].stddev,\n",
      "                self.hparams.standardization_coefficients[\n",
      "                    \"refractive_indices_imag\"\n",
      "                ].stddev,\n",
      "                self.hparams.standardization_coefficients[\"thicknesses\"].stddev,\n",
      "                self.hparams.standardization_coefficients[\"wavelengths_um\"].stddev,\n",
      "                1,\n",
      "                1,\n",
      "            ]\n",
      "        )\n",
      "        return mean_tensors, stddev_tensors\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/__init__.py\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/structure_from_rta_bands_generator.py\n",
      "from typing import Dict, Tuple\n",
      "\n",
      "import torch\n",
      "from torch import Tensor\n",
      "\n",
      "from multilayerai.ml.data import VocabMappings\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.decoder import Decoder\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.encoder import Encoder\n",
      "\n",
      "\n",
      "class StructureFromRTABandsTransformerGenerator(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        vocab_mappings: VocabMappings,\n",
      "        num_layers: int,\n",
      "        embedding_size: int,\n",
      "        hidden_embedding_size: int,\n",
      "        num_heads: int,\n",
      "        ff_hidden_dim: int,\n",
      "        dropout_rate: float = 0.0,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self._validate_inputs(num_heads, hidden_embedding_size)\n",
      "\n",
      "        self._num_heads = num_heads\n",
      "        self._encoder = Encoder(\n",
      "            num_layers=num_layers,\n",
      "            embedding_size=embedding_size,\n",
      "            hidden_embedding_size=hidden_embedding_size,\n",
      "            num_heads=num_heads,\n",
      "            ff_hidden_dim=ff_hidden_dim,\n",
      "            dropout_rate=dropout_rate,\n",
      "            with_pos_enc=False,\n",
      "        )\n",
      "        self._decoder = Decoder(\n",
      "            vocab_size=len(vocab_mappings),\n",
      "            num_layers=num_layers,\n",
      "            hidden_embedding_size=hidden_embedding_size,\n",
      "            num_heads=num_heads,\n",
      "            ff_hidden_dim=ff_hidden_dim,\n",
      "            dropout_rate=dropout_rate,\n",
      "        )\n",
      "        self._materials_head = torch.nn.Linear(\n",
      "            hidden_embedding_size, len(vocab_mappings)\n",
      "        )\n",
      "        self._thicknesses_head = torch.nn.Linear(\n",
      "            hidden_embedding_size, len(vocab_mappings)\n",
      "        )\n",
      "        self._is_inf_head = torch.nn.Linear(hidden_embedding_size, len(vocab_mappings))\n",
      "\n",
      "    @staticmethod\n",
      "    def _validate_inputs(num_heads: int, hidden_embedding_size: int):\n",
      "        if num_heads is None or num_heads <= 0:\n",
      "            raise ValueError(f\"num_heads must be a positive integer, got: {num_heads}\")\n",
      "        if hidden_embedding_size % num_heads != 0:\n",
      "            raise ValueError(\n",
      "                f\"hidden_embedding_size must be divisible by num_heads, got {hidden_embedding_size} and {num_heads}\"\n",
      "            )\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        band_requirements: Tensor,\n",
      "        target_tensor: Tensor,\n",
      "    ) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "        input_padding_arr = torch.where(\n",
      "            band_requirements[:, :, -1].bool(), -torch.inf, 0\n",
      "        )\n",
      "        input_padding_mask = self._create_padding_mask(input_padding_arr)\n",
      "        context = self._encoder(band_requirements, input_padding_mask)\n",
      "        dec_output = self._decoder(target_tensor, context, input_padding_arr)\n",
      "        return (\n",
      "            self._materials_head(dec_output),  # logits\n",
      "            self._thicknesses_head(dec_output),\n",
      "            self._is_inf_head(dec_output),  # logits\n",
      "        )\n",
      "\n",
      "    def _create_padding_mask(self, arr: torch.Tensor) -> torch.Tensor:\n",
      "        mask = arr.unsqueeze(1).expand(-1, arr.size(1), -1)\n",
      "        return torch.repeat_interleave(mask, self._num_heads, dim=0)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/rta_predictor.py\n",
      "import torch\n",
      "from torch import Tensor\n",
      "\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.encoder import Encoder\n",
      "\n",
      "\n",
      "class RTATransformerPredictor(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        num_layers: int,\n",
      "        embedding_size: int,\n",
      "        hidden_embedding_size: int,\n",
      "        num_heads: int,\n",
      "        ff_hidden_dim: int,\n",
      "        dropout_rate: float = 0.0,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self._validate_inputs(num_heads, hidden_embedding_size)\n",
      "        self._num_heads = num_heads\n",
      "        self._encoder = Encoder(\n",
      "            num_layers,\n",
      "            embedding_size,\n",
      "            hidden_embedding_size,\n",
      "            num_heads,\n",
      "            ff_hidden_dim,\n",
      "            dropout_rate,\n",
      "            with_pos_enc=True,\n",
      "        )\n",
      "        self._final_layer = torch.nn.Linear(hidden_embedding_size, 3)\n",
      "\n",
      "    @staticmethod\n",
      "    def _validate_inputs(num_heads: int, hidden_embedding_size: int):\n",
      "        if num_heads is None or num_heads <= 0:\n",
      "            raise ValueError(f\"num_heads must be a positive integer, got: {num_heads}\")\n",
      "        if hidden_embedding_size % num_heads != 0:\n",
      "            raise ValueError(\n",
      "                f\"hidden_embedding_size must be divisible by num_heads, got {hidden_embedding_size} and {num_heads}\"\n",
      "            )\n",
      "\n",
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        padding_arr = self._create_padding_array(x)\n",
      "        padding_mask = self._create_padding_mask(padding_arr)\n",
      "        x = self._encoder(x, padding_mask)\n",
      "        last_non_padding_idx = padding_arr.isinf().logical_not().sum(dim=1) - 1\n",
      "        return torch.softmax(\n",
      "            self._final_layer(x[torch.arange(x.size(0)), last_non_padding_idx]), dim=-1\n",
      "        )\n",
      "\n",
      "    @staticmethod\n",
      "    def _create_padding_array(x: torch.Tensor) -> torch.Tensor:\n",
      "        arr = x[:, :, -1] == 1\n",
      "        return torch.where(arr, -torch.inf, 0)\n",
      "\n",
      "    def _create_padding_mask(self, arr: torch.Tensor) -> torch.Tensor:\n",
      "        mask = arr.unsqueeze(1).expand(-1, arr.size(1), -1)\n",
      "        return torch.repeat_interleave(mask, self._num_heads, dim=0)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/__init__.py\n",
      "from multilayerai.ml.model.backbone.transformer.rta_predictor import (\n",
      "    RTATransformerPredictor,\n",
      ")\n",
      "from multilayerai.ml.model.backbone.transformer.structure_from_rta_bands_generator import (\n",
      "    StructureFromRTABandsTransformerGenerator,\n",
      ")\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/blocks/feed_forward.py\n",
      "import torch.nn\n",
      "\n",
      "\n",
      "class FeedForward(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self, input_embedding_size: int, output_embedding_size: int, ff_hidden_dim: int\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self._fc1 = torch.nn.Linear(input_embedding_size, ff_hidden_dim)\n",
      "        self._fc2 = torch.nn.Linear(ff_hidden_dim, output_embedding_size)\n",
      "        self._layer_norm = torch.nn.LayerNorm(output_embedding_size)\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        x_input = x\n",
      "        x = torch.relu(self._fc1(x))\n",
      "        x = self._fc2(x)\n",
      "        x = torch.add(x, x_input)\n",
      "        x = self._layer_norm(x)\n",
      "        return x\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/blocks/attention.py\n",
      "import torch.nn\n",
      "\n",
      "\n",
      "class CrossAttention(torch.nn.Module):\n",
      "    def __init__(self, embedding_size: int, num_heads: int, dropout_rate: float):\n",
      "        super().__init__()\n",
      "        self._mha = torch.nn.MultiheadAttention(\n",
      "            embedding_size, num_heads, batch_first=True, dropout=dropout_rate\n",
      "        )\n",
      "        self._layer_norm = torch.nn.LayerNorm(embedding_size)\n",
      "\n",
      "    def forward(self, x: torch.Tensor, context: torch.Tensor, attn_mask: torch.Tensor):\n",
      "        x_input = x\n",
      "        x, _ = self._mha(query=x, key=context, value=context, attn_mask=attn_mask)\n",
      "        x = torch.add(x, x_input)\n",
      "        return self._layer_norm(x)\n",
      "\n",
      "\n",
      "class GlobalSelfAttention(torch.nn.Module):\n",
      "    def __init__(self, embedding_size: int, num_heads: int, dropout_rate: float):\n",
      "        super().__init__()\n",
      "        self._mha = torch.nn.MultiheadAttention(\n",
      "            embedding_size, num_heads, batch_first=True, dropout=dropout_rate\n",
      "        )\n",
      "        self._layer_norm = torch.nn.LayerNorm(embedding_size)\n",
      "\n",
      "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor):\n",
      "        x_input = x\n",
      "        x, _ = self._mha(query=x, key=x, value=x, attn_mask=attn_mask)\n",
      "        x = torch.add(x, x_input)\n",
      "        return self._layer_norm(x)\n",
      "\n",
      "\n",
      "class CausalSelfAttention(torch.nn.Module):\n",
      "    def __init__(self, embedding_size: int, num_heads: int, dropout_rate: float):\n",
      "        super().__init__()\n",
      "        self._mha = torch.nn.MultiheadAttention(\n",
      "            embedding_size, num_heads, batch_first=True, dropout=dropout_rate\n",
      "        )\n",
      "        self._layer_norm = torch.nn.LayerNorm(embedding_size)\n",
      "\n",
      "    def forward(self, x: torch.Tensor):\n",
      "        attn_mask = torch.nn.Transformer.generate_square_subsequent_mask(x.size(1)).to(\n",
      "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
      "        )\n",
      "        x_input = x\n",
      "        x, _ = self._mha(query=x, key=x, value=x, attn_mask=attn_mask)\n",
      "        x = torch.add(x, x_input)\n",
      "        return self._layer_norm(x)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/blocks/encoder.py\n",
      "from typing import Tuple\n",
      "\n",
      "import torch.nn\n",
      "\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.attention import (\n",
      "    GlobalSelfAttention,\n",
      ")\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.feed_forward import FeedForward\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.positional import (\n",
      "    PositionalEncoding,\n",
      ")\n",
      "\n",
      "\n",
      "class Encoder(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        num_layers: int,\n",
      "        embedding_size: int,\n",
      "        hidden_embedding_size: int,\n",
      "        num_heads: int,\n",
      "        ff_hidden_dim: int,\n",
      "        dropout_rate: float,\n",
      "        with_pos_enc: bool,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self._with_pos_enc = with_pos_enc\n",
      "        if with_pos_enc:\n",
      "            self._positional_encoded = PositionalEncoding(\n",
      "                max_len=128, embedding_size=embedding_size\n",
      "            )\n",
      "        self._embedding_dim_adjuster = (\n",
      "            torch.nn.Linear(embedding_size, hidden_embedding_size)\n",
      "            if embedding_size != hidden_embedding_size\n",
      "            else None\n",
      "        )\n",
      "        self._layers = torch.nn.ModuleList(\n",
      "            [\n",
      "                EncoderLayer(\n",
      "                    hidden_embedding_size,\n",
      "                    hidden_embedding_size,\n",
      "                    num_heads,\n",
      "                    ff_hidden_dim,\n",
      "                    dropout_rate,\n",
      "                )\n",
      "                for _ in range(num_layers)\n",
      "            ]\n",
      "        )\n",
      "        self._dropout = torch.nn.Dropout(dropout_rate)\n",
      "        self._num_heads = num_heads\n",
      "\n",
      "    def forward(\n",
      "        self, x: torch.Tensor, padding_mask: torch.Tensor\n",
      "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
      "        x = self._positional_encoded(x) if self._with_pos_enc else x\n",
      "        if self._embedding_dim_adjuster is not None:\n",
      "            x = self._embedding_dim_adjuster(x)\n",
      "        x = self._dropout(x)\n",
      "        for layer in self._layers:\n",
      "            x = layer(x, padding_mask)\n",
      "        return x\n",
      "\n",
      "\n",
      "class EncoderLayer(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        input_embedding_size: int,\n",
      "        output_embedding_size: int,\n",
      "        num_heads: int,\n",
      "        ff_hidden_dim: int,\n",
      "        dropout_rate: float,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self._self_attention = GlobalSelfAttention(\n",
      "            input_embedding_size, num_heads, dropout_rate\n",
      "        )\n",
      "        self._feed_forward = FeedForward(\n",
      "            input_embedding_size, output_embedding_size, ff_hidden_dim\n",
      "        )\n",
      "\n",
      "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor) -> torch.Tensor:\n",
      "        x = self._self_attention(x, attn_mask=attn_mask)\n",
      "        x = self._feed_forward(x)\n",
      "        return x\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/blocks/__init__.py\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/blocks/positional.py\n",
      "import math\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class PositionalEmbedding(torch.nn.Module):\n",
      "    def __init__(self, vocab_size: int, embedding_size: int, max_len: int = 128):\n",
      "        super().__init__()\n",
      "        self._embedding = torch.nn.Embedding(vocab_size, embedding_size)\n",
      "        # + 2 for encoding thickness and is_inf thickness flag, appended to the embedding\n",
      "        self._positional_encoding = PositionalEncoding(max_len, embedding_size + 2)\n",
      "        self._embedding_size = embedding_size + 2\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        material = x[:, :, 0].int()\n",
      "        thickness_info = x[:, :, 1:]\n",
      "        embedding = self._embedding(material)\n",
      "        x = torch.cat([embedding, thickness_info], dim=-1)\n",
      "        x = math.sqrt(self._embedding_size) * x\n",
      "        return self._positional_encoding(x)\n",
      "\n",
      "\n",
      "class PositionalEncoding(torch.nn.Module):\n",
      "    def __init__(self, max_len: int, embedding_size: int):\n",
      "        super().__init__()\n",
      "        position = torch.arange(max_len).unsqueeze(1)\n",
      "        div_term = torch.exp(\n",
      "            torch.arange(0, embedding_size, 2) * (-math.log(10000.0) / embedding_size)\n",
      "        )\n",
      "        self._encoding = torch.zeros(max_len, embedding_size).to(\n",
      "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
      "        )\n",
      "        self._encoding[:, 0::2] = torch.sin(position * div_term)\n",
      "        self._encoding[:, 1::2] = torch.cos(\n",
      "            position * (div_term if embedding_size % 2 == 0 else div_term[:-1])\n",
      "        )\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        return x + self._encoding[: x.size(1)]\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/transformer/blocks/decoder.py\n",
      "import torch.nn\n",
      "\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.attention import (\n",
      "    CausalSelfAttention,\n",
      "    CrossAttention,\n",
      ")\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.feed_forward import FeedForward\n",
      "from multilayerai.ml.model.backbone.transformer.blocks.positional import (\n",
      "    PositionalEmbedding,\n",
      ")\n",
      "\n",
      "\n",
      "class Decoder(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        vocab_size: int,\n",
      "        num_layers: int,\n",
      "        hidden_embedding_size: int,\n",
      "        num_heads: int,\n",
      "        ff_hidden_dim: int,\n",
      "        dropout_rate: float,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self._positional_embedding = PositionalEmbedding(\n",
      "            vocab_size, hidden_embedding_size, max_len=128\n",
      "        )\n",
      "        # + 2 for encoding thickness and is_inf thickness flag, appended to the embedding\n",
      "        self._embedding_dim_adjuster = torch.nn.Linear(\n",
      "            hidden_embedding_size + 2, hidden_embedding_size\n",
      "        )\n",
      "        self._layers = torch.nn.ModuleList(\n",
      "            [\n",
      "                DecoderLayer(\n",
      "                    hidden_embedding_size,\n",
      "                    hidden_embedding_size,\n",
      "                    num_heads,\n",
      "                    ff_hidden_dim,\n",
      "                    dropout_rate,\n",
      "                )\n",
      "                for _ in range(num_layers)\n",
      "            ]\n",
      "        )\n",
      "        self._dropout = torch.nn.Dropout(dropout_rate)\n",
      "        self._num_heads = num_heads\n",
      "\n",
      "    def forward(\n",
      "        self, x: torch.Tensor, context: torch.Tensor, context_padding_arr: torch.Tensor\n",
      "    ) -> torch.Tensor:\n",
      "        context_padding_mask = self._create_padding_mask(x, context_padding_arr)\n",
      "        x = self._positional_embedding(x)\n",
      "        x = self._embedding_dim_adjuster(x)\n",
      "        x = self._dropout(x)\n",
      "        for layer in self._layers:\n",
      "            x = layer(x, context, context_padding_mask)\n",
      "        return x\n",
      "\n",
      "    def _create_padding_mask(\n",
      "        self, x: torch.Tensor, context_padding_arr: torch.Tensor\n",
      "    ) -> torch.Tensor:\n",
      "        mask = context_padding_arr.unsqueeze(1).expand(-1, x.size(1), -1)\n",
      "        return torch.repeat_interleave(mask, self._num_heads, dim=0)\n",
      "\n",
      "\n",
      "class DecoderLayer(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        input_embedding_size: int,\n",
      "        output_embedding_size: int,\n",
      "        num_heads: int,\n",
      "        ff_hidden_dim: int,\n",
      "        dropout_rate: float,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self._causal_self_attention = CausalSelfAttention(\n",
      "            input_embedding_size,\n",
      "            num_heads,\n",
      "            dropout_rate,\n",
      "        )\n",
      "        self._cross_attention = CrossAttention(\n",
      "            input_embedding_size,\n",
      "            num_heads,\n",
      "            dropout_rate,\n",
      "        )\n",
      "        self._feed_forward = FeedForward(\n",
      "            input_embedding_size, output_embedding_size, ff_hidden_dim\n",
      "        )\n",
      "\n",
      "    def forward(\n",
      "        self, x: torch.Tensor, context: torch.Tensor, attn_mask: torch.Tensor\n",
      "    ) -> torch.Tensor:\n",
      "        x = self._causal_self_attention(x)\n",
      "        x = self._cross_attention(x, context, attn_mask)\n",
      "        x = self._feed_forward(x)\n",
      "        return x\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/recurrent/rta_predictor.py\n",
      "import torch\n",
      "from torch import Tensor\n",
      "\n",
      "\n",
      "class RTARecurrentPredictor(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        recurrent_class: torch.nn.Module,\n",
      "        input_size: int,\n",
      "        hidden_embedding_size: int,\n",
      "        bidirectional: bool,\n",
      "        num_hidden_layers: int,\n",
      "        hidden_layer_size: int,\n",
      "        num_stacked_recurrent_layers: int = 1,\n",
      "        dropout_rate: float = 0.0,\n",
      "    ):\n",
      "        self._validate_inputs(recurrent_class)\n",
      "\n",
      "        super().__init__()\n",
      "        self._recurrent_class = recurrent_class\n",
      "        self.rnn = recurrent_class(\n",
      "            input_size=input_size,\n",
      "            hidden_size=hidden_embedding_size,\n",
      "            bidirectional=bidirectional,\n",
      "            batch_first=True,\n",
      "            num_layers=num_stacked_recurrent_layers,\n",
      "            dropout=dropout_rate,\n",
      "        )\n",
      "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
      "        self.hidden_layers = torch.nn.ModuleList(\n",
      "            [\n",
      "                torch.nn.Linear(\n",
      "                    in_features=hidden_embedding_size\n",
      "                    * (2 if bidirectional else 1)\n",
      "                    * num_stacked_recurrent_layers,\n",
      "                    out_features=hidden_layer_size,\n",
      "                )\n",
      "                if idx == 0\n",
      "                else torch.nn.Linear(\n",
      "                    in_features=hidden_layer_size,\n",
      "                    out_features=3,\n",
      "                )\n",
      "                if idx == num_hidden_layers\n",
      "                else torch.nn.Linear(\n",
      "                    in_features=hidden_layer_size,\n",
      "                    out_features=hidden_layer_size,\n",
      "                )\n",
      "                for idx in range(\n",
      "                    num_hidden_layers + 1\n",
      "                )  # +1 accounts for the output neuron\n",
      "            ]\n",
      "        )\n",
      "\n",
      "    @staticmethod\n",
      "    def _validate_inputs(recurrent_class: torch.nn.Module):\n",
      "        valid_recurrent_classes = [torch.nn.LSTM, torch.nn.GRU, torch.nn.RNN]\n",
      "        if recurrent_class not in valid_recurrent_classes:\n",
      "            raise ValueError(\n",
      "                f\"Invalid recurrent class. Must be one of: {''.join([c.__name__ for c in valid_recurrent_classes])}\"\n",
      "            )\n",
      "\n",
      "    def forward(self, input: Tensor) -> Tensor:\n",
      "        if self._recurrent_class == torch.nn.LSTM:\n",
      "            _, (x, _) = self.rnn(input)\n",
      "        else:\n",
      "            _, x = self.rnn(input)\n",
      "        x = x.view(x.size(1), x.size(0) * x.size(-1))\n",
      "        for layer in self.hidden_layers:\n",
      "            x = self.dropout(x)\n",
      "            x = torch.relu(layer(x))\n",
      "        return torch.softmax(x, dim=-1)\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/backbone/recurrent/__init__.py\n",
      "from multilayerai.ml.model.backbone.recurrent.rta_predictor import RTARecurrentPredictor\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/callback/__init__.py\n",
      "from multilayerai.ml.model.callback.metrics_history import MetricsHistoryCallback\n",
      "\n",
      "\n",
      "# *=*=*=*=*= /home/cupofcoffee/PycharmProjects/multilayer-ai-msc/multilayerai/ml/model/callback/metrics_history.py\n",
      "import copy\n",
      "import json\n",
      "import os\n",
      "\n",
      "import pytorch_lightning as pl\n",
      "from typing import Dict, List, Optional, Tuple\n",
      "\n",
      "\n",
      "class MetricsHistoryCallback(pl.Callback):\n",
      "    def __init__(self, output_dir: Optional[str] = None):\n",
      "        super().__init__()\n",
      "        self._metrics = {key: [] for key in self.keys()}\n",
      "        self._output_dir = output_dir\n",
      "\n",
      "    @property\n",
      "    def metrics(self) -> Dict[str, List[float]]:\n",
      "        return copy.deepcopy(self._metrics)\n",
      "\n",
      "    @staticmethod\n",
      "    def keys() -> Tuple[str, str]:\n",
      "        return \"loss\", \"val_loss\"\n",
      "\n",
      "    def on_train_epoch_end(self, trainer, pl_module):\n",
      "        self._metrics[\"loss\"].append(trainer.callback_metrics.get(\"loss\").item())\n",
      "        self._save_metrics()\n",
      "\n",
      "    def on_validation_epoch_end(self, trainer, pl_module):\n",
      "        if trainer.sanity_checking:\n",
      "            return\n",
      "        self._metrics[\"val_loss\"].append(\n",
      "            trainer.callback_metrics.get(\"val_loss\").item()\n",
      "        )\n",
      "        self._save_metrics()\n",
      "\n",
      "    def _save_metrics(self):\n",
      "        if self._output_dir is not None:\n",
      "            with open(os.path.join(self._output_dir, \"metrics.json\"), \"w\") as f:\n",
      "                json.dump(self.metrics, f)\n",
      "</code>\n",
      "\n",
      "You are given the above dump of part of a machine learning project's repository. Your goal is to modify parts of this code or add new\n",
      "code in order to implement RLHF for the StructureGeneratorFromRTABandsLightningWrapper model. The model should use the reward function\n",
      "implemented by TmmFeedbackEnvironment. You are free to use external libraries if this facilitates your implementation. If you introduce\n",
      "changes in the code, you don't have to paste the contents of the whole file. It's enough to mention only what must be changed.\n",
      "\n",
      "\u001b[1m\u001b[92mSPECIALIST\u001b[0m\n",
      "To implement RLHF (Reinforcement Learning from Human Feedback) for the StructureGeneratorFromRTABandsLightningWrapper model using the reward function from TmmFeedbackEnvironment, we need to make several modifications and additions to the existing codebase. Here's a step-by-step approach to implement RLHF:\n",
      "\n",
      "1. Create a new file called `rlhf_structure_generator.py` in the `multilayerai/ml/model/` directory.\n",
      "\n",
      "2. In this new file, we'll create a new class called `RLHFStructureGenerator` that will wrap the existing `StructureGeneratorFromRTABandsLightningWrapper` and implement the RLHF logic. Here's the implementation:\n",
      "\n",
      "```python\n",
      "# multilayerai/ml/model/rlhf_structure_generator.py\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from typing import Dict, List\n",
      "\n",
      "from multilayerai.ml.model import StructureGeneratorFromRTABandsLightningWrapper\n",
      "from multilayerai.ml.rl.environment import TmmFeedbackEnvironment\n",
      "\n",
      "class RLHFStructureGenerator(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        base_model: StructureGeneratorFromRTABandsLightningWrapper,\n",
      "        environment: TmmFeedbackEnvironment,\n",
      "        learning_rate: float = 1e-5,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self.base_model = base_model\n",
      "        self.environment = environment\n",
      "        self.optimizer = torch.optim.Adam(self.base_model.parameters(), lr=learning_rate)\n",
      "\n",
      "    def forward(self, band_requirements: torch.Tensor, target_tensor: torch.Tensor):\n",
      "        return self.base_model(band_requirements, target_tensor)\n",
      "\n",
      "    def generate_structure(self, band_requirements: torch.Tensor):\n",
      "        materials = []\n",
      "        thicknesses = []\n",
      "        is_inf = []\n",
      "\n",
      "        target_tensor = torch.zeros_like(band_requirements)  # Initialize with zeros\n",
      "        \n",
      "        for _ in range(self.environment._max_layers):\n",
      "            material_logits, thickness_pred, is_inf_pred = self(band_requirements, target_tensor)\n",
      "            \n",
      "            material_probs = F.softmax(material_logits[:, -1], dim=-1)\n",
      "            material = torch.multinomial(material_probs, 1)\n",
      "            thickness = thickness_pred[:, -1, material.item()]\n",
      "            inf_prob = torch.sigmoid(is_inf_pred[:, -1, material.item()])\n",
      "            \n",
      "            materials.append(material.item())\n",
      "            thicknesses.append(thickness.item())\n",
      "            is_inf.append(inf_prob.item() > 0.5)\n",
      "            \n",
      "            if material.item() == self.base_model.hparams.vocab_mappings.material_to_idx[\"<EOS>\"]:\n",
      "                break\n",
      "            \n",
      "            # Update target_tensor for the next iteration\n",
      "            target_tensor = torch.cat([target_tensor, torch.zeros_like(target_tensor[:, :1])], dim=1)\n",
      "            target_tensor[:, -1, 0] = material\n",
      "            target_tensor[:, -1, 1] = thickness\n",
      "            target_tensor[:, -1, 2] = inf_prob\n",
      "        \n",
      "        return materials, thicknesses, is_inf\n",
      "\n",
      "    def rlhf_step(self, band_requirements: torch.Tensor):\n",
      "        self.optimizer.zero_grad()\n",
      "        \n",
      "        materials, thicknesses, is_inf = self.generate_structure(band_requirements)\n",
      "        \n",
      "        # Convert the generated structure to actions\n",
      "        actions = [\n",
      "            AddLayerAction(material=self.base_model.hparams.vocab_mappings.idx_to_material[m], thickness_um=t)\n",
      "            for m, t, inf in zip(materials, thicknesses, is_inf) if not inf\n",
      "        ]\n",
      "        actions.append(Action(material=\"<EOS>\"))\n",
      "        \n",
      "        # Get the reward from the environment\n",
      "        _, reward, _, _ = self.environment.step(actions[-1])\n",
      "        for action in reversed(actions[:-1]):\n",
      "            _, step_reward, _, _ = self.environment.step(action)\n",
      "            reward += step_reward\n",
      "        \n",
      "        # Calculate the loss\n",
      "        loss = -reward  # We want to maximize the reward, so we minimize the negative reward\n",
      "        \n",
      "        loss.backward()\n",
      "        self.optimizer.step()\n",
      "        \n",
      "        return loss.item(), reward\n",
      "\n",
      "    def train_rlhf(self, band_requirements: List[torch.Tensor], num_episodes: int):\n",
      "        for episode in range(num_episodes):\n",
      "            total_loss = 0\n",
      "            total_reward = 0\n",
      "            for br in band_requirements:\n",
      "                loss, reward = self.rlhf_step(br)\n",
      "                total_loss += loss\n",
      "                total_reward += reward\n",
      "            \n",
      "            avg_loss = total_loss / len(band_requirements)\n",
      "            avg_reward = total_reward / len(band_requirements)\n",
      "            \n",
      "            print(f\"Episode {episode + 1}/{num_episodes}, Avg Loss: {avg_loss:.4f}, Avg Reward: {avg_reward:.4f}\")\n",
      "```\n",
      "\n",
      "3. Modify the `StructureGeneratorFromRTABandsLightningWrapper` class to make it compatible with the RLHF wrapper:\n",
      "\n",
      "```python\n",
      "# multilayerai/ml/model/structure_generator_from_rta_bands_lightning_wrapper.py\n",
      "\n",
      "class StructureGeneratorFromRTABandsLightningWrapper(pl.LightningModule):\n",
      "    # ... (existing code) ...\n",
      "\n",
      "    def forward(self, band_requirements: Tensor, target_tensor: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "        return self._backbone(band_requirements, target_tensor)\n",
      "\n",
      "    # ... (rest of the existing code) ...\n",
      "```\n",
      "\n",
      "4. Update the `TmmFeedbackEnvironment` class to handle the new action structure:\n",
      "\n",
      "```python\n",
      "# multilayerai/ml/rl/environment.py\n",
      "\n",
      "class TmmFeedbackEnvironment(gym.Env):\n",
      "    # ... (existing code) ...\n",
      "\n",
      "    def step(self, action: Action):\n",
      "        self._validate_action(action)\n",
      "        if isinstance(action, AddLayerAction):\n",
      "            self._action_history.append(action)\n",
      "            reward = 0\n",
      "            terminated = False\n",
      "        elif action.material == \"<EOS>\":\n",
      "            reward = self._calculate_reward()\n",
      "            terminated = True\n",
      "        else:\n",
      "            raise ValueError(f\"Invalid action: {action}\")\n",
      "        \n",
      "        truncated = False\n",
      "        observation = self._get_obs()\n",
      "        return observation, reward, terminated, truncated\n",
      "\n",
      "    # ... (rest of the existing code) ...\n",
      "```\n",
      "\n",
      "5. Create a new training script to use the RLHF structure generator:\n",
      "\n",
      "```python\n",
      "# train_rlhf_structure_generator.py\n",
      "\n",
      "import torch\n",
      "from multilayerai.ml.model import StructureGeneratorFromRTABandsLightningWrapper\n",
      "from multilayerai.ml.model.rlhf_structure_generator import RLHFStructureGenerator\n",
      "from multilayerai.ml.rl.environment import TmmFeedbackEnvironment\n",
      "from multilayerai.entity import Requirement\n",
      "from multilayerai.ml.data.bands import RTABandsRequirementsBuilder\n",
      "\n",
      "# Load the pre-trained StructureGeneratorFromRTABandsLightningWrapper\n",
      "base_model = StructureGeneratorFromRTABandsLightningWrapper.load_from_checkpoint(\"path/to/checkpoint.ckpt\")\n",
      "\n",
      "# Create the TmmFeedbackEnvironment\n",
      "goal = [\n",
      "    Requirement(...),  # Define your requirements here\n",
      "    # ...\n",
      "]\n",
      "environment = TmmFeedbackEnvironment(\n",
      "    goal=goal,\n",
      "    refractive_index_assets_dir=\"path/to/refractive_index_assets\",\n",
      "    wavelength_granularity_um=0.1,\n",
      ")\n",
      "\n",
      "# Create the RLHF structure generator\n",
      "rlhf_generator = RLHFStructureGenerator(base_model, environment)\n",
      "\n",
      "# Prepare training data (band requirements)\n",
      "band_requirements_builder = RTABandsRequirementsBuilder()\n",
      "# Add your requirements here\n",
      "band_requirements = [\n",
      "    torch.tensor(band_requirements_builder.to_vector()).unsqueeze(0)\n",
      "    for _ in range(100)  # Create 100 different band requirements\n",
      "]\n",
      "\n",
      "# Train the RLHF model\n",
      "rlhf_generator.train_rlhf(band_requirements, num_episodes=1000)\n",
      "\n",
      "# Save the trained model\n",
      "torch.save(rlhf_generator.state_dict(), \"rlhf_structure_generator.pth\")\n",
      "```\n",
      "\n",
      "This implementation adds RLHF to the existing StructureGeneratorFromRTABandsLightningWrapper model by creating a wrapper class `RLHFStructureGenerator`. The wrapper uses the base model to generate structures and then fine-tunes it using the rewards from the TmmFeedbackEnvironment.\n",
      "\n",
      "The main changes and additions are:\n",
      "\n",
      "1. Created a new `RLHFStructureGenerator` class that wraps the base model and implements the RLHF logic.\n",
      "2. Modified the `StructureGeneratorFromRTABandsLightningWrapper` to expose its forward method.\n",
      "3. Updated the `TmmFeedbackEnvironment` to handle the new action structure.\n",
      "4. Created a new training script to demonstrate how to use the RLHF structure generator.\n",
      "\n",
      "This implementation allows for fine-tuning the pre-trained model using reinforcement learning, potentially improving its performance on specific tasks defined by the TmmFeedbackEnvironment's reward function.\n",
      "\n",
      "\u001b[1m\u001b[91mCRITIC\u001b[0m\n",
      "Thank you for providing this detailed implementation of RLHF for the StructureGeneratorFromRTABandsLightningWrapper model. I've carefully reviewed your code and explanation, and I have a few observations and suggestions for improvement:\n",
      "\n",
      "1. Error handling: The code doesn't include error handling for potential exceptions that might occur during the RLHF process. It would be beneficial to add try-except blocks to handle potential errors gracefully.\n",
      "\n",
      "2. Logging: While there's some basic printing of episode results, it would be helpful to implement more comprehensive logging, perhaps using Python's logging module or a dedicated logging library.\n",
      "\n",
      "3. Hyperparameters: The learning rate is hardcoded in the RLHFStructureGenerator class. It might be better to make this and other hyperparameters (like num_episodes) configurable.\n",
      "\n",
      "4. Validation: There's no validation step in the training process. It would be useful to implement a validation phase to monitor the model's performance on unseen data.\n",
      "\n",
      "5. Early stopping: Consider implementing an early stopping mechanism to prevent overfitting and save computation time.\n",
      "\n",
      "6. Gradient clipping: To prevent exploding gradients, it might be beneficial to implement gradient clipping in the optimization step.\n",
      "\n",
      "7. Documentation: While the code is generally clear, adding docstrings to classes and methods would improve readability and maintainability.\n",
      "\n",
      "8. Type hinting: Some functions are missing type hints, which could be added for consistency and better code understanding.\n",
      "\n",
      "9. Saving checkpoints: The current implementation only saves the final model. It might be useful to save checkpoints during training.\n",
      "\n",
      "10. Memory management: For long training sessions with many episodes, it might be necessary to implement some form of memory management, especially if working with large datasets.\n",
      "\n",
      "Here's an example of how you might implement some of these suggestions in the `RLHFStructureGenerator` class:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from typing import Dict, List, Tuple\n",
      "import logging\n",
      "from torch.nn.utils import clip_grad_norm_\n",
      "\n",
      "class RLHFStructureGenerator(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        base_model: StructureGeneratorFromRTABandsLightningWrapper,\n",
      "        environment: TmmFeedbackEnvironment,\n",
      "        learning_rate: float = 1e-5,\n",
      "        max_grad_norm: float = 1.0,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self.base_model = base_model\n",
      "        self.environment = environment\n",
      "        self.optimizer = torch.optim.Adam(self.base_model.parameters(), lr=learning_rate)\n",
      "        self.max_grad_norm = max_grad_norm\n",
      "        self.logger = logging.getLogger(__name__)\n",
      "\n",
      "    def forward(self, band_requirements: torch.Tensor, target_tensor: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
      "        return self.base_model(band_requirements, target_tensor)\n",
      "\n",
      "    def generate_structure(self, band_requirements: torch.Tensor) -> Tuple[List[int], List[float], List[bool]]:\n",
      "        # ... (existing code) ...\n",
      "\n",
      "    def rlhf_step(self, band_requirements: torch.Tensor) -> Tuple[float, float]:\n",
      "        try:\n",
      "            self.optimizer.zero_grad()\n",
      "            \n",
      "            materials, thicknesses, is_inf = self.generate_structure(band_requirements)\n",
      "            \n",
      "            # ... (existing code) ...\n",
      "            \n",
      "            loss.backward()\n",
      "            clip_grad_norm_(self.parameters(), self.max_grad_norm)\n",
      "            self.optimizer.step()\n",
      "            \n",
      "            return loss.item(), reward\n",
      "        except Exception as e:\n",
      "            self.logger.error(f\"Error in RLHF step: {str(e)}\")\n",
      "            return 0.0, 0.0\n",
      "\n",
      "    def train_rlhf(self, band_requirements: List[torch.Tensor], num_episodes: int, validation_data: List[torch.Tensor] = None):\n",
      "        best_val_reward = float('-inf')\n",
      "        for episode in range(num_episodes):\n",
      "            total_loss = 0\n",
      "            total_reward = 0\n",
      "            for br in band_requirements:\n",
      "                loss, reward = self.rlhf_step(br)\n",
      "                total_loss += loss\n",
      "                total_reward += reward\n",
      "            \n",
      "            avg_loss = total_loss / len(band_requirements)\n",
      "            avg_reward = total_reward / len(band_requirements)\n",
      "            \n",
      "            self.logger.info(f\"Episode {episode + 1}/{num_episodes}, Avg Loss: {avg_loss:.4f}, Avg Reward: {avg_reward:.4f}\")\n",
      "            \n",
      "            if validation_data:\n",
      "                val_reward = self.validate(validation_data)\n",
      "                self.logger.info(f\"Validation Reward: {val_reward:.4f}\")\n",
      "                if val_reward > best_val_reward:\n",
      "                    best_val_reward = val_reward\n",
      "                    self.save_checkpoint(f\"best_model_episode_{episode+1}.pth\")\n",
      "\n",
      "    def validate(self, validation_data: List[torch.Tensor]) -> float:\n",
      "        total_reward = 0\n",
      "        with torch.no_grad():\n",
      "            for br in validation_data:\n",
      "                _, reward = self.rlhf_step(br)\n",
      "                total_reward += reward\n",
      "        return total_reward / len(validation_data)\n",
      "\n",
      "    def save_checkpoint(self, filename: str):\n",
      "        torch.save({\n",
      "            'model_state_dict': self.state_dict(),\n",
      "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
      "        }, filename)\n",
      "```\n",
      "\n",
      "These modifications address several of the points I mentioned earlier. However, there's still room for improvement, particularly in areas like early stopping and more sophisticated memory management.\n",
      "\n",
      "Given these observations and suggestions, I cannot fully agree with the initial implementation. While it provides a solid foundation, incorporating these improvements would make the RLHF implementation more robust, efficient, and easier to maintain.\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[92mSPECIALIST\u001b[0m\n",
      "Thank you for your thorough review and excellent suggestions. I completely agree with your observations, and I appreciate the detailed feedback. You're absolutely right that the initial implementation, while functional, could be significantly improved in terms of robustness, efficiency, and maintainability. Let's address each of your points and incorporate them into an improved version of the `RLHFStructureGenerator` class.\n",
      "\n",
      "Here's an updated implementation that incorporates most of your suggestions:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from typing import Dict, List, Tuple, Optional\n",
      "import logging\n",
      "from torch.nn.utils import clip_grad_norm_\n",
      "from collections import deque\n",
      "import numpy as np\n",
      "\n",
      "class RLHFStructureGenerator(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        base_model: StructureGeneratorFromRTABandsLightningWrapper,\n",
      "        environment: TmmFeedbackEnvironment,\n",
      "        learning_rate: float = 1e-5,\n",
      "        max_grad_norm: float = 1.0,\n",
      "        patience: int = 10,\n",
      "        memory_size: int = 1000\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Initialize the RLHF Structure Generator.\n",
      "\n",
      "        Args:\n",
      "            base_model (StructureGeneratorFromRTABandsLightningWrapper): The base model to be fine-tuned.\n",
      "            environment (TmmFeedbackEnvironment): The environment providing rewards.\n",
      "            learning_rate (float): Learning rate for the optimizer.\n",
      "            max_grad_norm (float): Maximum norm for gradient clipping.\n",
      "            patience (int): Number of episodes to wait before early stopping.\n",
      "            memory_size (int): Size of the memory buffer for experience replay.\n",
      "        \"\"\"\n",
      "        super().__init__()\n",
      "        self.base_model = base_model\n",
      "        self.environment = environment\n",
      "        self.optimizer = torch.optim.Adam(self.base_model.parameters(), lr=learning_rate)\n",
      "        self.max_grad_norm = max_grad_norm\n",
      "        self.patience = patience\n",
      "        self.memory = deque(maxlen=memory_size)\n",
      "        self.logger = logging.getLogger(__name__)\n",
      "        self.logger.setLevel(logging.INFO)\n",
      "\n",
      "    def forward(self, band_requirements: torch.Tensor, target_tensor: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
      "        \"\"\"Forward pass of the model.\"\"\"\n",
      "        return self.base_model(band_requirements, target_tensor)\n",
      "\n",
      "    def generate_structure(self, band_requirements: torch.Tensor) -> Tuple[List[int], List[float], List[bool]]:\n",
      "        \"\"\"Generate a structure based on the given band requirements.\"\"\"\n",
      "        materials, thicknesses, is_inf = [], [], []\n",
      "        target_tensor = torch.zeros_like(band_requirements)\n",
      "\n",
      "        for _ in range(self.environment._max_layers):\n",
      "            material_logits, thickness_pred, is_inf_pred = self(band_requirements, target_tensor)\n",
      "            \n",
      "            material_probs = F.softmax(material_logits[:, -1], dim=-1)\n",
      "            material = torch.multinomial(material_probs, 1)\n",
      "            thickness = thickness_pred[:, -1, material.item()]\n",
      "            inf_prob = torch.sigmoid(is_inf_pred[:, -1, material.item()])\n",
      "            \n",
      "            materials.append(material.item())\n",
      "            thicknesses.append(thickness.item())\n",
      "            is_inf.append(inf_prob.item() > 0.5)\n",
      "            \n",
      "            if material.item() == self.base_model.hparams.vocab_mappings.material_to_idx[\"<EOS>\"]:\n",
      "                break\n",
      "            \n",
      "            target_tensor = torch.cat([target_tensor, torch.zeros_like(target_tensor[:, :1])], dim=1)\n",
      "            target_tensor[:, -1, 0] = material\n",
      "            target_tensor[:, -1, 1] = thickness\n",
      "            target_tensor[:, -1, 2] = inf_prob\n",
      "\n",
      "        return materials, thicknesses, is_inf\n",
      "\n",
      "    def rlhf_step(self, band_requirements: torch.Tensor) -> Tuple[float, float]:\n",
      "        \"\"\"Perform a single RLHF step.\"\"\"\n",
      "        try:\n",
      "            self.optimizer.zero_grad()\n",
      "            \n",
      "            materials, thicknesses, is_inf = self.generate_structure(band_requirements)\n",
      "            \n",
      "            actions = [\n",
      "                AddLayerAction(material=self.base_model.hparams.vocab_mappings.idx_to_material[m], thickness_um=t)\n",
      "                for m, t, inf in zip(materials, thicknesses, is_inf) if not inf\n",
      "            ]\n",
      "            actions.append(Action(material=\"<EOS>\"))\n",
      "            \n",
      "            _, reward, _, _ = self.environment.step(actions[-1])\n",
      "            for action in reversed(actions[:-1]):\n",
      "                _, step_reward, _, _ = self.environment.step(action)\n",
      "                reward += step_reward\n",
      "            \n",
      "            loss = -reward\n",
      "            \n",
      "            loss.backward()\n",
      "            clip_grad_norm_(self.parameters(), self.max_grad_norm)\n",
      "            self.optimizer.step()\n",
      "            \n",
      "            self.memory.append((band_requirements, reward))\n",
      "            \n",
      "            return loss.item(), reward\n",
      "        except Exception as e:\n",
      "            self.logger.error(f\"Error in RLHF step: {str(e)}\")\n",
      "            return 0.0, 0.0\n",
      "\n",
      "    def train_rlhf(self, band_requirements: List[torch.Tensor], num_episodes: int, validation_data: Optional[List[torch.Tensor]] = None):\n",
      "        \"\"\"Train the model using RLHF.\"\"\"\n",
      "        best_val_reward = float('-inf')\n",
      "        no_improve_count = 0\n",
      "        \n",
      "        for episode in range(num_episodes):\n",
      "            total_loss = 0\n",
      "            total_reward = 0\n",
      "            \n",
      "            for br in band_requirements:\n",
      "                loss, reward = self.rlhf_step(br)\n",
      "                total_loss += loss\n",
      "                total_reward += reward\n",
      "            \n",
      "            avg_loss = total_loss / len(band_requirements)\n",
      "            avg_reward = total_reward / len(band_requirements)\n",
      "            \n",
      "            self.logger.info(f\"Episode {episode + 1}/{num_episodes}, Avg Loss: {avg_loss:.4f}, Avg Reward: {avg_reward:.4f}\")\n",
      "            \n",
      "            if validation_data:\n",
      "                val_reward = self.validate(validation_data)\n",
      "                self.logger.info(f\"Validation Reward: {val_reward:.4f}\")\n",
      "                if val_reward > best_val_reward:\n",
      "                    best_val_reward = val_reward\n",
      "                    self.save_checkpoint(f\"best_model_episode_{episode+1}.pth\")\n",
      "                    no_improve_count = 0\n",
      "                else:\n",
      "                    no_improve_count += 1\n",
      "                \n",
      "                if no_improve_count >= self.patience:\n",
      "                    self.logger.info(f\"Early stopping at episode {episode + 1}\")\n",
      "                    break\n",
      "            \n",
      "            if episode % 10 == 0:\n",
      "                self.experience_replay()\n",
      "\n",
      "    def validate(self, validation_data: List[torch.Tensor]) -> float:\n",
      "        \"\"\"Validate the model on the given validation data.\"\"\"\n",
      "        total_reward = 0\n",
      "        with torch.no_grad():\n",
      "            for br in validation_data:\n",
      "                _, reward = self.rlhf_step(br)\n",
      "                total_reward += reward\n",
      "        return total_reward / len(validation_data)\n",
      "\n",
      "    def save_checkpoint(self, filename: str):\n",
      "        \"\"\"Save a checkpoint of the model.\"\"\"\n",
      "        torch.save({\n",
      "            'model_state_dict': self.state_dict(),\n",
      "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
      "        }, filename)\n",
      "\n",
      "    def experience_replay(self, batch_size: int = 32):\n",
      "        \"\"\"Perform experience replay to improve sample efficiency.\"\"\"\n",
      "        if len(self.memory) < batch_size:\n",
      "            return\n",
      "\n",
      "        batch = random.sample(self.memory, batch_size)\n",
      "        batch_requirements, batch_rewards = zip(*batch)\n",
      "\n",
      "        batch_requirements = torch.stack(batch_requirements)\n",
      "        batch_rewards = torch.tensor(batch_rewards, device=self.device)\n",
      "\n",
      "        self.optimizer.zero_grad()\n",
      "        \n",
      "        materials, thicknesses, is_inf = self.generate_structure(batch_requirements)\n",
      "        \n",
      "        actions = [\n",
      "            AddLayerAction(material=self.base_model.hparams.vocab_mappings.idx_to_material[m], thickness_um=t)\n",
      "            for m, t, inf in zip(materials, thicknesses, is_inf) if not inf\n",
      "        ]\n",
      "        actions.append(Action(material=\"<EOS>\"))\n",
      "        \n",
      "        loss = -torch.mean(batch_rewards)\n",
      "        \n",
      "        loss.backward()\n",
      "        clip_grad_norm_(self.parameters(), self.max_grad_norm)\n",
      "        self.optimizer.step()\n",
      "```\n",
      "\n",
      "This improved implementation addresses most of your suggestions:\n",
      "\n",
      "1. Error handling: Try-except block in the `rlhf_step` method.\n",
      "2. Logging: Using Python's logging module for more comprehensive logging.\n",
      "3. Hyperparameters: More hyperparameters are now configurable in the constructor.\n",
      "4. Validation: Implemented a validation step in the training process.\n",
      "5. Early stopping: Implemented based on the validation reward and a patience parameter.\n",
      "6. Gradient clipping: Implemented in the optimization step.\n",
      "7. Documentation: Added docstrings to the class and its methods.\n",
      "8. Type hinting: Added throughout the class.\n",
      "9. Saving checkpoints: Now saves the best model based on validation performance.\n",
      "10. Memory management: Implemented a simple experience replay mechanism to improve sample efficiency and manage memory usage.\n",
      "\n",
      "Additional improvements:\n",
      "\n",
      "- Added an experience replay mechanism to improve sample efficiency.\n",
      "- Implemented early stopping based on validation performance.\n",
      "- Made the code more modular by breaking it into smaller, focused methods.\n",
      "\n",
      "This implementation provides a more robust, efficient, and maintainable solution for RLHF with the StructureGeneratorFromRTABandsLightningWrapper model. However, there's always room for further improvement, such as more sophisticated memory management techniques, adaptive learning rates, or more advanced RL algorithms like PPO or SAC.\n",
      "\n",
      "\u001b[1m\u001b[91mCRITIC\u001b[0m\n",
      "Thank you for the comprehensive update to the RLHFStructureGenerator class. This revised implementation addresses most of the concerns I raised and incorporates several important improvements. Let's review the changes:\n",
      "\n",
      "1. Error handling: Properly implemented in the rlhf_step method.\n",
      "2. Logging: Utilizes Python's logging module effectively.\n",
      "3. Hyperparameters: More configurable parameters in the constructor, improving flexibility.\n",
      "4. Validation: Implemented and integrated into the training process.\n",
      "5. Early stopping: Implemented based on validation performance and patience.\n",
      "6. Gradient clipping: Correctly applied in the optimization step.\n",
      "7. Documentation: Docstrings added to the class and methods, enhancing readability.\n",
      "8. Type hinting: Applied consistently throughout the class.\n",
      "9. Saving checkpoints: Now saves the best model based on validation performance.\n",
      "10. Memory management: Implemented a basic experience replay mechanism.\n",
      "\n",
      "Additional improvements:\n",
      "- Experience replay mechanism for better sample efficiency.\n",
      "- Modular code structure with focused methods.\n",
      "\n",
      "These changes significantly enhance the robustness, efficiency, and maintainability of the implementation. The code now follows better software engineering practices and incorporates essential machine learning techniques.\n",
      "\n",
      "However, there are a few minor points that could be further improved or clarified:\n",
      "\n",
      "1. The `device` attribute is used in the `experience_replay` method, but it's not defined in the constructor. It would be good to add this as a parameter or determine it automatically.\n",
      "\n",
      "2. The `random` module is used in `experience_replay`, but it's not imported at the top of the file.\n",
      "\n",
      "3. Consider adding a method to load a checkpoint, complementing the `save_checkpoint` method.\n",
      "\n",
      "4. The `generate_structure` method could potentially benefit from being a `@torch.no_grad()` context to save memory during inference.\n",
      "\n",
      "5. You might want to consider adding a way to adjust the learning rate during training, such as a learning rate scheduler.\n",
      "\n",
      "Here's a snippet addressing these points:\n",
      "\n",
      "```python\n",
      "import random\n",
      "import torch\n",
      "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
      "\n",
      "class RLHFStructureGenerator(torch.nn.Module):\n",
      "    def __init__(\n",
      "        self,\n",
      "        base_model: StructureGeneratorFromRTABandsLightningWrapper,\n",
      "        environment: TmmFeedbackEnvironment,\n",
      "        learning_rate: float = 1e-5,\n",
      "        max_grad_norm: float = 1.0,\n",
      "        patience: int = 10,\n",
      "        memory_size: int = 1000,\n",
      "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
      "    ):\n",
      "        # ... (previous init code) ...\n",
      "        self.device = device\n",
      "        self.to(self.device)\n",
      "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='max', factor=0.1, patience=5)\n",
      "\n",
      "    @torch.no_grad()\n",
      "    def generate_structure(self, band_requirements: torch.Tensor) -> Tuple[List[int], List[float], List[bool]]:\n",
      "        # ... (previous code) ...\n",
      "\n",
      "    def train_rlhf(self, band_requirements: List[torch.Tensor], num_episodes: int, validation_data: Optional[List[torch.Tensor]] = None):\n",
      "        # ... (previous code) ...\n",
      "        if validation_data:\n",
      "            val_reward = self.validate(validation_data)\n",
      "            self.logger.info(f\"Validation Reward: {val_reward:.4f}\")\n",
      "            self.scheduler.step(val_reward)\n",
      "        # ... (rest of the method) ...\n",
      "\n",
      "    def load_checkpoint(self, filename: str):\n",
      "        \"\"\"Load a checkpoint of the model.\"\"\"\n",
      "        checkpoint = torch.load(filename, map_location=self.device)\n",
      "        self.load_state_dict(checkpoint['model_state_dict'])\n",
      "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
      "```\n",
      "\n",
      "With these final adjustments, I believe the implementation is now very solid and addresses all the major points we've discussed. The code is well-structured, includes essential ML techniques, and follows good software engineering practices. \n",
      "\n",
      "Given these improvements, I can now say that I fully agree with this implementation of RLHF for the StructureGeneratorFromRTABandsLightningWrapper model.\n",
      "\n",
      "<AGREE>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{TextFormatting.BOLD}TASK{TextFormatting.END}\\n{task}\")\n",
    "while True:\n",
    "    specialist_resp = llm(specialist_memory)\n",
    "    specialist_memory.append(specialist_resp)\n",
    "    print(f\"{TextFormatting.BOLD}{TextFormatting.GREEN}SPECIALIST{TextFormatting.END}\\n{specialist_resp.content}\\n\")\n",
    "    critic_memory.append(HumanMessage(specialist_resp.content))\n",
    "    critic_resp = llm(critic_memory)\n",
    "    critic_memory.append(critic_resp)\n",
    "    print(f\"{TextFormatting.BOLD}{TextFormatting.RED}CRITIC{TextFormatting.END}\\n{critic_resp.content}\")\n",
    "    specialist_memory.append(HumanMessage(critic_resp.content))\n",
    "    if \"<AGREE>\" in critic_resp.content:\n",
    "        break\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69830c1-11ac-40fb-a3e8-d96962c9aeff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bwmsc",
   "language": "python",
   "name": "bwmsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
